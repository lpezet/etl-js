## (11/11/2021) Azure Pipelines

Finally found the time to check out Azure Pipelines.
It's really amazing (and similar to etl-js).

Taken directly from their documentation:

- A **trigger** tells a Pipeline to run.
- A **pipeline** is made up of one or more **stages**. A pipeline can deploy to one or more **environments**.
- A **stage** is a way of organizing **jobs** in a pipeline and each stage can have one or more jobs.
- Each **job** runs on one **agent**. A job can also be agentless.
- Each **agent** runs a job that contains one or more **steps**.
- A **step** can be a **task** or **script** and is the smallest building block of a pipeline.
- A **task** is a pre-packaged script that performs an action, such as invoking a REST API or publishing a build artifact.
- An **artifact** is a collection of files or packages published by a **run**.

### Equivalents

Here's a mapping table between Azure Pipelines and ETL-JS:

| Azure Pipelines | ETL-JS      | Notes                                                                                        |
| --------------- | ----------- | -------------------------------------------------------------------------------------------- |
| trigger         |             | No equivalent right now in ETL-JS.                                                           |
| pipeline        | etlSet      | This is like "default" or user-defined set of activities grouped under a key.                |
| stage           | activity    | This is our activities that contain tasks in ETL-JS                                          |
| job             | ?           | I'm not sure what would be the equivalent here. Maybe the "steps" within our **activity**??? |
| agent           | executor?   | This is the equivalent of our Executors although Azure has a different approach here (1).    |
| steps           | mod         |                                                                                              |
| task or script  | mod action? |                                                                                              |
| artifact        |             | No equivalent.                                                                               |
| run             |             | No equivalent.                                                                               |

(1). It seems here that it's more about an Executor in charge of executing something, vs. something that needs an Executor to function.
From Azure Pipelines documentation:

> When your build or deployment runs, the system begins one or more jobs. An agent is computing infrastructure with installed agent software that runs one job at a time. For example, your job could run on a Microsoft-hosted Ubuntu agent.

#### stages

In Azure Pipelines, **stage** is defined as such:

```yaml
stages:
- stage: string  # name of the stage, A-Z, a-z, 0-9, and underscore
  displayName: string  # friendly name to display in the UI
  dependsOn: string | [ string ]
  condition: string
  pool: string | pool
  variables: { string: string } | [ variable | variableReference ]
  jobs: [ job | templateReference]
```

Dependencies are interesting:

> When you define multiple stages in a pipeline, by default, they run sequentially in the order in which you define them in the YAML file. The exception to this is when you add dependencies. With dependencies, stages run in the order of the dependsOn requirements.

In ETL-JS, we could add this **dependsOn** and even **condition** aspect in our activities.

At first sight, I'm not sure I like the way Azure implemented **Conditions** (https://docs.microsoft.com/en-us/azure/devops/pipelines/process/stages?view=azure-devops&tabs=yaml#conditions).

```yaml
stages:
  - stage: A

  # stage B runs if A fails
  - stage: B
    condition: failed()

  # stage C runs if B succeeds
  - stage: C
    dependsOn:
      - A
      - B
    condition: succeeded('B')
```

In ETL-JS, **activities** are defined as such:

```yaml
activityIndex: pActivityIndex
totalActivities: pTotalActivities
activityId: oActivityId
template:
  steps:
    step1:
      commands:
        a_b_c:
          ...
      files:
      ...
    step2:
      commands:
        e_f_g:
          ...
      ...
context: pContext
```

Only the content of _template_ is specified by user, the rest is provided by _etl_ itself.
A template (or pipeline, in Azure parlance) would look like this in ETL-JS:

```yaml
etlSets:
  default:
    - activity1
    - activity2
  other:
    - activity2
    - activity3
activity1:
  steps:
    step1:
      commands:
        a_b_c:
          ...
      files:
      ...
    step2:
      commands:
        e_f_g:
          ...
      ...
activity2:
  ...
```

The idea of the _steps_ was two fold: 1) to be able to specify other aspects to an activity, like a time limit, etc. and not be in the middle of "commands" steps for example, and 2) a way to have multiple combos of mods without affecting each other.
Because it's a map, we can't have:

```yaml
activity1:
  commands:
    a_b_c:
      ...
  files:
    ...
  commands: # problem here!!!!
    d_e_f:
      ...
```

#### jobs

In Azure Pipelines, \*jobs\*\* are defined as such:

```yaml
- job: string  # name of the job, A-Z, a-z, 0-9, and underscore
  displayName: string  # friendly name to display in the UI
  dependsOn: string | [ string ]
  condition: string
  strategy:
    parallel: # parallel strategy
    matrix: # matrix strategy
    maxParallel: number # maximum number simultaneous matrix legs to run
    # note: `parallel` and `matrix` are mutually exclusive
    # you may specify one or the other; including both is an error
    # `maxParallel` is only valid with `matrix`
  continueOnError: boolean  # 'true' if future jobs should run even if this job fails; defaults to 'false'
  pool: pool # agent pool
  workspace:
    clean: outputs | resources | all # what to clean up before the job runs
  container: containerReference # container to run this job inside
  timeoutInMinutes: number # how long to run the job before automatically cancelling
  cancelTimeoutInMinutes: number # how much time to give 'run always even if cancelled tasks' before killing them
  variables: { string: string } | [ variable | variableReference ]
  steps: [ script | bash | pwsh | powershell | checkout | task | templateReference ]
  services: { string: string | container } # container resources to run as a service container
  uses: # Any resources (repos or pools) required by this job that are not already referenced
    repositories: [ string ] # Repository references to Azure Git repositories
    pools: [ string ] # Pool names, typically when using a matrix strategy for the job
```

#### steps, tasks, and scripts

One big difference is that **task**s in Azure are like libraries.
Creating a task is like creating a new npm/node lib. See https://docs.microsoft.com/en-us/azure/devops/extend/develop/add-build-task?view=azure-devops for more details.
It's very similar to ETL-JS, except as of right now, mods are _baked_ into ETL-JS.

> In YAML pipelines, you refer to tasks by name. If a name matches both an in-box task and a custom task, the in-box task will take precedence. You can use the task GUID or a fully-qualified name for the custom task to avoid this risk:

This is what it looks like i Azure Pipelines to refer to a **task** (source: https://docs.microsoft.com/en-us/azure/devops/pipelines/process/tasks?view=azure-devops&tabs=yaml#custom-tasks):

```yaml
steps:
  - task: myPublisherId.myExtensionId.myContributionId.myTaskName@1 #format example
  - task: qetza.replacetokens.replacetokens-task.replacetokens@3 #working example
```

Each task offers some control options:

```yaml
- task: string # reference to a task and version, e.g. "VSBuild@1"
  condition: expression # see below
  continueOnError: boolean # 'true' if future steps should run even if this step fails; defaults to 'false'
  enabled: boolean # whether or not to run this step; defaults to 'true'
  timeoutInMinutes: number # how long to wait before timing out the task
  target: string # 'host' or the name of a container resource to target
```

This is what a simple task main code look like. This code runs when the task is called.

```ts
import tl = require("azure-pipelines-task-lib/task");

async function run() {
  try {
    const inputString: string | undefined = tl.getInput("samplestring", true);
    if (inputString == "bad") {
      tl.setResult(tl.TaskResult.Failed, "Bad input was given");
      return;
    }
    console.log("Hello", inputString);
  } catch (err) {
    tl.setResult(tl.TaskResult.Failed, err.message);
  }
}

run();
```

Here's a snippet to define steps:

```yaml
steps:
  - script: date /t
    displayName: Get the date
  - script: dir
    workingDirectory: $(Agent.BuildDirectory)
    displayName: List contents of a folder
  - script: |
      set MYVAR=foo
      set
    displayName: Set a variable and then display all
    env:
      aVarFromYaml: someValue
```

Equivalent in ETL-JS:

```yaml
commands:
  get_the_date:
    command: date /t
  list_contants_of_a_folder:
    command: dir
    cwd: "{{ Agent.BuildDirectory }}"
  set_a_variable_and_then_display_all:
    command: |
      set MYVAR=foo
      set
    env:
      aVarFromYaml: someValue
```
